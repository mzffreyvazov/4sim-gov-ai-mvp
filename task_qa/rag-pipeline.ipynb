{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables FIRST, before any LangChain imports\n",
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "\n",
    "# Now import LangChain modules\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1f7e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LANGSMITH_API_KEY = os.environ[\"LANGSMITH_API_KEY\"]\n",
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "LANGSMITH_TRACING = os.environ[\"LANGSMITH_TRACING\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd5eed",
   "metadata": {},
   "source": [
    "### LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "314dfcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65269121",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to Azerbaijani. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9bcf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_google = init_chat_model(\n",
    "    \"gemini-2.0-flash-exp\", \n",
    "    model_provider=\"google_genai\",\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a0ce3",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d70ead58",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ollama = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6976156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NCAFE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# The rest of your code\n",
    "embedding_hg = HuggingFaceEmbeddings(\n",
    "     model_name=\"LocalDoc/az-en-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1ad81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedding_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83723c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NCAFE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# file_path = \"execution-of-sentences.pdf\"\n",
    "file_path = \"emek-mecellesi-1-20.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# we can later optimize the prompt, for now lets use predefined prompt from hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm_google.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afa15396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bailiff of the court executes community service punishments. Fines are executed by the\n",
      "legislation upon the presentation of the institution or body executing the main punishment. The\n",
      "executive officer at the place of residence of the convict executes the punishment in the form of\n",
      "deprivation of the right to hold a certain position or engage in certain activity.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which institutions and bodies are responsible for executing different types of punishments?\"\n",
    "\n",
    "response = graph.invoke({\"question\": question})\n",
    "import textwrap\n",
    "wrapped_text = textwrap.fill(response[\"answer\"], width=100)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
